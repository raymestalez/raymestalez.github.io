<!DOCTYPE html>
<html lang="en">
  
<head>
  <meta charset="utf-8" />
  
  <title>digitalmind</title>

  <!-- Import css and scripts  -->
  <link rel="stylesheet" href="/theme/css/foundation.css" />
  <link rel="stylesheet" href="/theme/css/main.css" />
  <script src="/theme/js/vendor/jquery.js" type="text/javascript"></script>
    
</head>
  
<body>
<div id="orange-line"></div>
  <header>
      <div class="row" >
        <div class="large-6 columns" >
          <a href="/"><img src="/theme/img/logo_notagline.png" /></a>
        </div>
        <div class="large-6 columns" id="mainMenu">
	  Home Articles About
	</div>
      </div>
  </header>
  
<div id="page"  class="postPage">
    <div class="row">
      <div class="large-12 columns">
        <h1 id="blogTitle"> Deep Learning </h1>
        <hr />
	<h2>Resources</h2>
<h4>General ML introduction</h4>
<ul>
<li>
<p>Andrew Ng <a href="https://www.coursera.org/course/ml">Machine Learning course</a> on Coursera.<br />
  And his <a href="http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=ufldl">course on Deep learning </a></p>
</li>
<li>
<p><a href="https://class.coursera.org/machlearning-001/lecture/preview">Pedro Domingos ML course</a> </p>
</li>
<li>
<p>Book "<a href="http://www.amazon.com/Programming-Collective-Intelligence-Building-Applications/dp/0596529325">Programming Collective Intelligence</a>" </p>
</li>
<li>
<p>TutsPlus course "<a href="http://code.tutsplus.com/courses/machine-learning-distilled">Machine Learning Distilled</a>"</p>
</li>
</ul>
<h4>Deep Learning Basics</h4>
<ul>
<li>
<p>Geoffrey Hinton's coursera course "<a href="https://class.coursera.org/neuralnets-2012-001/lecture">Neural Networks for Machine Learning</a>"</p>
</li>
<li>
<p>MIT Book on <a href="http://www.iro.umontreal.ca/~bengioy/dlbook/">Deep Learning</a></p>
</li>
<li>
<p><a href="http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial">UFLDL tutorial by Stanford</a> (alternative <a href="http://deeplearning.stanford.edu/tutorial/">link</a>)</p>
</li>
<li>
<p><a href="http://deeplearning.net/tutorial/">deeplearning.net tutorials</a></p>
</li>
</ul>
<h4>Other</h4>
<ul>
<li>
<p>NYU Course on <a href="http://techtalks.tv/deep_learning_nyu_spring_2014/">Deep Learning</a></p>
</li>
<li>
<p>Book "<a href="http://neuralnetworksanddeeplearning.com">Neural Networks and Deep Learning</a>" by Michael Nielsen</p>
</li>
<li>
<p>Book Neural "<a href="http://www.amazon.com/Neural-Networks-Learning-Machines-Edition/dp/0131471392">Networks and Learning Machines</a>" by Simon O. Haykin</p>
</li>
<li>
<p><a href="http://deeplearning.net/reading-list/">deeplearning.net reading list</a></p>
</li>
</ul>
<h2>Prerequisites - Math</h2>
<ul>
<li>Calculus</li>
<li>Linear Algebra</li>
<li>Probability &amp; Statistics</li>
</ul>
<!--
## Topics

- General overview, terms, into, background.
    - What is ML? Applications of ML
        - Types of Learning: supervised/unsupervised learning
    - classification/regression(difference)
- ML Algorithms
    - Supervised Learning
      - Linear Regression with one variable
          - Model Representation
          - Cost function
          - Gradient Descent
      - Linear Regression with multiple variables
          - Gradient descent for multiple vectors
          - Features and polynomial regression
          - Normal Equation
      - Logistic Reression
      - k-Nearest Neighbor
      - Decision Tree
      - Naive Bayesian Classifiers

      - Support Vector Machines
      - Random Forests
    - Unsupervised Learning
      - k-Means Clustering
      - Hierarchical Clustering
      - Self-Organizing Maps
      - Apriori Association
- Deep Learning
  - Perceptron
    - Linear Regression
  - Gradient Descent
  - Stochastic Gradient descent
  - Multilayer Perceptrons
  - Backpropogation
  - Hidden Layer Representations

  - Neural Networks: Representation and learning
      - Neurons
      - Model representation
      - Cost function
      - Backpropogation algorithm
      - Gradient checking
      - Random Initialization

  - Perceptron

  - Artificial Neural Networks Representation
  - General Regression Neural Networks
  - Feed-Forward Neural Networks
- Other/General ML
  - ML Systems design
    - Error  Analysis
  - Dimensionality Reduction
  - Anomaly Detection
  - Recommender Systems
-->

<!-- To Sort, other topics
- Neural networks:
  - Types of neurons,
  - Learning rules for binary,
  - linear and logistic neurons,
  - FeedForward Neural Networks (FFNN)
  - Backpropagation (BP),
  - BP with weight constraints.
  - Recurrent Neural Networks (RNN),
  - FFNN interpretation for RNN,
  - BP through time,
  - Exploding/Vanishing gradients.
- Energy-based models:
  - Hopfield Nets (HN),
  - Learning & unlearning in HN,
  - HN with hidden units,
  - Simulated annealing,
  - Boltzmann machines (BM),
  - BM Learning algorithm.
- Deep Neural Networks:
  - Deep Boltzmann Machines (DBM),
  - Restricted Boltzmann Machines (RBM),
  - Contrastive Divergence and variants (PCD, CD_k),
  - Stacked RBMs for pre-training,
  - Discriminative finetuning using BP.
- Nonlinear Dimensionality Reduction:
  - Autoencoders (AE),
  - AE for document retrieval/visualization,
  - AE for semantic hashing
- Other:
  - Minibatch gradient descent,
  - Momentum method,
  - Adaptive Learning rates,
  - Limiting size of weights,
  - Weight decay,
  - Early stopping,
  - Noise as regularizer,
  - Dropouts,
  - Bagging/Averaging and Boosting,
  - Bias-variance tradeoff,
  - Implementation on GPGPUs. 
-->

<h2>Roadmap</h2>
<h3>Basic Math</h3>
<ul>
<li>Calculus</li>
<li>Linear Algebra</li>
<li>Probability &amp; Statistics</li>
</ul>
<h3>Andrew Ng course</h3>
<p>Andrew Ng <a href="https://www.coursera.org/course/ml">Machine Learning course</a>,<br />
supplemented with his <a href="http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=ufldl">course on Deep learning </a>, and Neural Networks explanation from <a href="https://class.coursera.org/machlearning-001/lecture/preview">Pedro Domingos ML course</a>.(for things that are unclear).</p>
<p><br/>
Projects:
<br/><br/></p>
<h4>Linear Regression</h4>
<p><a href="http://metacademy.org/graphs/concepts/linear_regression#focus=x6e7glql&amp;mode=explore"><img alt="linreg" src="{{" title="site.baseurl }}/images/deep-learning/linear-regressoin.png" /></a></p>
<ul>
<li>Vectors</li>
<li>Dot product</li>
<li>Matrix Multiplication</li>
</ul>
<div style="clear: both;"></div>

<h4>Logistic Regression</h4>
<p><a href="http://metacademy.org/concepts/logistic_regression"><img alt="linreg" src="{{" title="site.baseurl }}/images/deep-learning/logistic-regressoin.png" /></a></p>
<ul>
<li>Linear Regression as Maximum Likelihood<ul>
<li>Probability</li>
<li>Conditional Probability
n    - Independent Events</li>
<li></li>
<li>Multiple Integrals</li>
<li>Multivariate Distributions</li>
<li>Random Variables</li>
<li>Independent Random Variables</li>
<li></li>
<li>Expectation and variance</li>
<li>Gaussian Distribution</li>
<li>Optimization Problems</li>
<li>Maximum likelihood</li>
</ul>
</li>
<li>Binary Linear Classifiers</li>
<li>Generalization</li>
<li>Ridge regression</li>
</ul>
<div style="clear: both;"></div>

<h4>Feed Forward Neural Network</h4>
<p><a href="http://metacademy.org/graphs/concepts/feed_forward_neural_nets#focus=m9abwewv&amp;mode=explore"><img alt="linreg" src="{{" title="site.baseurl }}/images/deep-learning/feed-forward-ann.png" /></a>
  - basic function expansions</p>
<div style="clear: both;"></div>

<h4>Backpropagation</h4>
<p><a href="http://metacademy.org/graphs/concepts/backpropagation#focus=iplkhc1b&amp;mode=explore"><img alt="linreg" src="{{" title="site.baseurl }}/images/deep-learning/backpropagation.png" /></a></p>
<ul>
<li>Linear approximation<ul>
<li>functions of several variables</li>
<li>partial derivatives</li>
<li>limits and continuity in R^n</li>
</ul>
</li>
<li>Gradient Descent</li>
<li>Stochastic Gradient Descent</li>
<li>Chain Rule</li>
</ul>
<div style="clear: both;"></div>

<h2>Hinton + SP</h2>
<p><a href="http://metacademy.org/roadmaps/rgrosse/deep_learning">http://metacademy.org/roadmaps/rgrosse/deep_learning</a>
<a href="http://www.metacademy.org/graphs/concepts/deep_belief_networks"><img alt="linreg" src="{{" title="site.baseurl }}/images/deep-learning/deep-belief.png" /></a></p>
<ul>
<li>Bayesian Networks<ul>
<li>Bayes Rule</li>
</ul>
</li>
<li>Markov Chains<ul>
<li>Conditional Distribution</li>
<li>Conditional Independence</li>
<li>Monte Carlo estimation</li>
<li>Markov Chain Monte Carlo</li>
</ul>
</li>
<li>Restricted Boltzmann Machines<ul>
<li>Gibbs Sampling</li>
<li>Markov Random Fields</li>
<li>Inference in MRFs</li>
<li>MRF parameter learning</li>
</ul>
</li>
</ul>
<p>// Recurrent Neural Network - ?</p>
<div style="clear: both;"></div>

<script>
function prepareList() {
  $('body').find('li:has(ul)')
    .click( function(event) {
        if (this == event.target) {
            $(this).toggleClass('expanded');
            $(this).children('ul').toggle('medium');
        }
        return false;
    })
    .addClass('collapsed');
    //.children('ul').hide();
  };

  $(document).ready( function() {
      prepareList();
  });
</script>

<style>
.collapsed {
    cursor: pointer;
    <!-- content:' ►';  -->

    <!-- background: url({{ site.baseurl }}/images/small_right_arrow.gif) no-repeat left top; -->
    <!-- padding: 3px 0px 3px 20px; -->
    <!-- list-style: none; -->
    }

.collapsed {
cursor: pointer;
    <!-- content:' ►';  -->
    <!-- background: url({{ site.baseurl }}/images/small_right_arrow.gif) no-repeat left top;p -->
    <!-- padding: 3px 0px 3px 20px; -->
    <!-- list-style: none; -->
    }

.entry img {
float:left;
}
<!-- max-width: 400px;
max-height: 400px; -->


</style>

<!--
list-style-image: url({{ site.baseurl }}/images/small_right_arrow.gif);
 -->	
      </div>
    </div>      
</div>    
    
  
  <footer>
  </footer>
</body>
</html>